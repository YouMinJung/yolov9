{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# VSCode에서만 사용 가능한 건지 확인 필요\n",
    "FILE = Path(__vsc_ipynb_file__).resolve()\n",
    "ROOT = FILE.parents[1]\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['nc', 'depth_multiple', 'width_multiple', 'activation', 'anchors', 'backbone', 'head'])\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "MODEL_FILE = '/mnt/hdd01/hyeongdo/workspace/yolov9/models/detect/yolov9.yaml'\n",
    "with open(MODEL_FILE, encoding='ascii', errors='ignore') as f:\n",
    "    model_yaml = yaml.safe_load(f)\n",
    "\n",
    "print(type(model_yaml))\n",
    "print(model_yaml.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tibetsandfox.tistory.com/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of layers: 29\n",
      "index(28) of layer args: [[31, 34, 37, 16, 19, 22], 1, 'DualDDetect', ['nc']]\n",
      "\n",
      "3 nc\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "m = model_yaml['head']\n",
    "# print(len(m))\n",
    "model_yaml['head']\n",
    "# model_yaml['backbone'].__next__ # AttributeError: 'list' object has no attribute '__next__'\n",
    "model_iter = iter(model_yaml['head'])\n",
    "# print(model_iter.__next__())\n",
    "# print(next(model_iter))\n",
    "layers = []\n",
    "for layer in model_iter:\n",
    "    layers.append(layer)\n",
    "print(f'number of layers: {len(layers)}')\n",
    "dbg_layer_idx = len(layers)-1\n",
    "print(f'index({dbg_layer_idx}) of layer args: {layers[dbg_layer_idx]}')\n",
    "f, n, m, args = layers[dbg_layer_idx]\n",
    "\n",
    "for j, a in enumerate(args):\n",
    "    # print(j, a)\n",
    "    # print(args[j])\n",
    "    with contextlib.suppress(NameError):\n",
    "        args[j] = eval(a) if isinstance(a, str) else a\n",
    "    # print(args[j])\n",
    "\n",
    "print(*args[1:])\n",
    "\n",
    "# CBLinear\n",
    "out_channel = args[0]\n",
    "in_channel = 3\n",
    "args = [in_channel, out_channel, *args[1:]]\n",
    "# print(args)\n",
    "print(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.yolo import parse_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1         0  models.common.Silence                   []                            \n",
      "  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
      "  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n",
      "  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      "  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n",
      "  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      "  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n",
      "  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n",
      "  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n",
      " 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n",
      " 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n",
      " 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n",
      " 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n",
      " 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n",
      " 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
      " 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n",
      " 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      " 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n",
      " 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n",
      " 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      " 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n",
      " 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n",
      " 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n",
      " 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n",
      " 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n",
      " 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n",
      " 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n",
      " 29                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n",
      " 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 31          [-1, 25]  1         0  models.common.Concat                    [1]                           \n",
      " 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n",
      " 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 34          [-1, 22]  1         0  models.common.Concat                    [1]                           \n",
      " 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n",
      " 36                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      " 37          [-1, 32]  1         0  models.common.Concat                    [1]                           \n",
      " 38                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n",
      " 39                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 40          [-1, 29]  1         0  models.common.Concat                    [1]                           \n",
      " 41                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n",
      " 42      [35, 38, 41]  1   5552320  models.yolo.DDetect                     [80, [256, 512, 512]]         \n"
     ]
    }
   ],
   "source": [
    "input_channel = [3]\n",
    "\n",
    "model, saved = parse_model(model_yaml, input_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 정의 파일에서 마지막 detect 리스트의 첫 번째 원소를 가져와서 이전 레이어가 아닌 경우에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 38, 41]\n"
     ]
    }
   ],
   "source": [
    "# 모델의 마지막 원소는 Head이다.\n",
    "m = model[-1] # DualDDetect\n",
    "# print(m)\n",
    "# 가져온 Head block 모듈이 이전 레이어에 연결되어 있는 레이어가 아니면 \n",
    "# # detect\n",
    "# [[35, 38, 41], 1, DDetect, [nc]],  # Detect(P3, P4, P5)\n",
    "print(m.f) # layer(s) from previous layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모듈의 stride를 계산하기 위해 forward를 한 번 호출해서 계산하는데, 왜 그렇게 하는지 이유는 모르겠음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구조가 정의되어 있는 yaml 파일을 읽어서 dict형의 자료로 변환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`models/yolo.py`\n",
    "\n",
    "```python\n",
    "class DetectionModel(BaseModel):\n",
    "    # model, input channels, number of classes\n",
    "    def __init__(self, cfg='yolo.yaml', ch=3, nc=None, anchors=None):\n",
    "        ...\n",
    "        if isinstance(cfg, dict):\n",
    "            self.yaml = cfg  # model dict\n",
    "        else:  # is *.yaml\n",
    "            import yaml  # for torch hub\n",
    "            self.yaml_file = Path(cfg).name\n",
    "            with open(cfg, encoding='ascii', errors='ignore') as f:\n",
    "                self.yaml = yaml.safe_load(f)  # model dict\n",
    "        ...\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델이 정의되어 있는 yaml 파일에 입력 레이어의 채널이 정의되어 있지 않으면 생성자로 전달한 채널 크기를 입력 레이어의 채널로 설정하고 그렇지 않으면 yaml 파일에 정의되어 있는 채널 크기를 입력 레이어의 채널러 설정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "        ch = self.yaml['ch'] = self.yaml.get('ch', ch)  # input channels\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 정의 파일에 정의된 클래스 수(`nc`)와 인스턴스 생성에서 전달한 클래스 수(`nc`)가 다르면\n",
    "```python\n",
    " self.yaml['nc']\n",
    "```\n",
    " 를 인스턴스 생성에서 전달받은 값으로 설정한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인스턴스 생성에서 `anchors` 값을 전달 받았으며 `self.yaml['anchor']`의 값을 전달 받은 값으로 변경한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train.py(102-117)`\n",
    "\n",
    "```python\n",
    "# hyp is path/to/hyp.yaml or hyp dictionary\n",
    "def train(hyp, opt, device, callbacks):\n",
    "    ...\n",
    "    check_suffix(weights, '.pt')  # check weights\n",
    "    pretrained = weights.endswith('.pt')\n",
    "    if pretrained:\n",
    "        with torch_distributed_zero_first(LOCAL_RANK):\n",
    "            weights = attempt_download(weights)  # download if not found locally\n",
    "        ckpt = torch.load(weights, map_location='cpu')  # load checkpoint to CPU to avoid CUDA memory leak\n",
    "        model = Model(cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
    "        exclude = ['anchor'] if (cfg or hyp.get('anchors')) and not resume else []  # exclude keys\n",
    "        csd = ckpt['model'].float().state_dict()  # checkpoint state_dict as FP32\n",
    "        csd = intersect_dicts(csd, model.state_dict(), exclude=exclude)  # intersect\n",
    "        model.load_state_dict(csd, strict=False)  # load\n",
    "        LOGGER.info(f'Transferred {len(csd)}/{len(model.state_dict())} items from {weights}')  # report\n",
    "    else:\n",
    "        model = Model(cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
    "    amp = check_amp(model)  # check AMP\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model`은 `DetectionModel`이다. (`models/yolo.py`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train.py(564-567)`\n",
    "\n",
    "```python\n",
    "def main(opt, callbacks=Callbacks()):\n",
    "    ...\n",
    "        with open(opt.hyp, errors='ignore') as f:\n",
    "            hyp = yaml.safe_load(f)  # load hyps dict\n",
    "            if 'anchors' not in hyp:  # anchors commented in hyp.yaml\n",
    "                hyp['anchors'] = 3\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evolove 모드에서 hyper-parameter 정의 파일에 anchorsr가 정의 되어 있지 않으면 기본값 3으로 설정한다. 일반 train에서는 파일 설정 원형 그대로 전달한다.\n",
    "\n",
    "만약 hyper-parameter 파일에 anchors 키가 선언되어 있고 값이 설정되어 있으면 모델 정의 yaml 파일에 정의되어 있는 anchors의 값이 이 값으로 대체 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`models/yolo.py(592-599)`\n",
    "\n",
    "```python\n",
    "class DetectionModel(BaseModel):\n",
    "    # model, input channels, number of classes\n",
    "    def __init__(self, cfg='yolo.yaml', ch=3, nc=None, anchors=None):\n",
    "        ...\n",
    "        if anchors:\n",
    "            LOGGER.info(f'Overriding model.yaml anchors with anchors={anchors}')\n",
    "            self.yaml['anchors'] = round(anchors)  # override yaml value\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "HYP_FILE = '/mnt/hdd01/hyeongdo/workspace/yolov9/data/hyps/hyp.scratch-high.yaml'\n",
    "with open(HYP_FILE, errors='ignore') as f:\n",
    "    hyp = yaml.safe_load(f)\n",
    "# pprint(hyp)\n",
    "print(hyp.get('anchors'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number(n)는 네트워크의 depth gain을 계산할 때 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`yolo.py (713-)`\n",
    "\n",
    "```python\n",
    "def parse_model(d, ch):  # model_dict, input_channels(3)\n",
    "    ...\n",
    "    for i, (f, n, m, args) in enumerate(d['backbone'] + d['head']):  # from, number, module, args\n",
    "    m = eval(m) if isinstance(m, str) else m  # eval strings\n",
    "    for j, a in enumerate(args):\n",
    "        with contextlib.suppress(NameError):\n",
    "            args[j] = eval(a) if isinstance(a, str) else a  # eval strings\n",
    "    ...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
