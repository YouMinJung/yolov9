{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.general import check_img_size, Profile, increment_path\n",
    "from utils.dataloaders import IMG_FORMATS, LoadImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "weights = '/work/src/yolov9/weights/yolov9-c-motsynth-48e-best.pt'\n",
    "dnn = False\n",
    "data = '/work/src/yolov9/data/yolo-anatomy.yaml'\n",
    "half = True\n",
    "imgsz = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "yolov9-c summary: 604 layers, 50698278 parameters, 0 gradients, 236.6 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride, names, pt = model.stride, model.names, model.pt\n",
    "imgsz = check_img_size(imgsz, s=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "vid_stride = 1\n",
    "source = '/work/dataset/VR-DRONE-v1.0.0.test/20221207/1Class/30m/30c/Crop_0030_030m_30c_3_4_00344.jpg'\n",
    "dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.warmup(imgsz=(bs, 3, imgsz, imgsz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage0_Silence_features.png... (3/3)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage1_Conv_features.png... (32/64)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage2_Conv_features.png... (32/128)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage3_RepNCSPELAN4_features.png... (32/256)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage4_ADown_features.png... (32/256)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage5_RepNCSPELAN4_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage6_ADown_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage7_RepNCSPELAN4_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage8_ADown_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage9_RepNCSPELAN4_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage10_SPPELAN_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage11_Upsample_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage12_Concat_features.png... (32/1024)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage13_RepNCSPELAN4_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage14_Upsample_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage15_Concat_features.png... (32/1024)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage16_RepNCSPELAN4_features.png... (32/256)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage17_ADown_features.png... (32/256)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage18_Concat_features.png... (32/768)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage19_RepNCSPELAN4_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage20_ADown_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage21_Concat_features.png... (32/1024)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage22_RepNCSPELAN4_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage26_Conv_features.png... (32/64)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage27_Conv_features.png... (32/128)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage28_RepNCSPELAN4_features.png... (32/256)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage29_ADown_features.png... (32/256)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage30_CBFuse_features.png... (32/256)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage31_RepNCSPELAN4_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage32_ADown_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage33_CBFuse_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage34_RepNCSPELAN4_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage35_ADown_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage36_CBFuse_features.png... (32/512)\n",
      "Saving /work/src/yolov9/runs/vis/Crop_0030_030m_30c_3_4_0034411/stage37_RepNCSPELAN4_features.png... (32/512)\n"
     ]
    }
   ],
   "source": [
    "project = '/work/src/yolov9/runs'\n",
    "name = 'vis'\n",
    "visualize = True\n",
    "exist_ok = True\n",
    "save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)\n",
    "\n",
    "augment = False\n",
    "dt = Profile(), Profile(), Profile()\n",
    "for path, im, im0s, vid_cap, s in dataset:\n",
    "    with dt[0]:\n",
    "        im = torch.from_numpy(im).to(model.device)\n",
    "        im = im.half() if model.fp16 else im.float()\n",
    "        im /= 255\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]\n",
    "    visualize = increment_path(save_dir/Path(path).stem, mkdir=True) if visualize else False\n",
    "    pred = model(im, augment=augment, visualize=visualize)\n",
    "    pred = pred[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv\n"
     ]
    }
   ],
   "source": [
    "module_type = 'Conv'\n",
    "\n",
    "if module_type not in ['Detect', 'CBLinear'] :\n",
    "    print(module_type)\n",
    "else:\n",
    "    print('Correct')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
